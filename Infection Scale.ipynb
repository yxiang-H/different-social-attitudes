{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# 为了保证x的取值范围是[epsilon,1],确保概率密度函数的积分为1\n",
    "def normalizing_constant(gamma, epsilon):\n",
    "    return (1 - epsilon**(1 - gamma)) / (1 - gamma)\n",
    "\n",
    "# 概率密度函数\n",
    "def pdf(gamma, epsilon):\n",
    "    normalizing_const = normalizing_constant(gamma, epsilon)\n",
    "    def normalized_pdf(x):\n",
    "        if not epsilon <= x <= 1.0:\n",
    "            return 0\n",
    "        return x**(-gamma) / normalizing_const\n",
    "    return normalized_pdf\n",
    "\n",
    "# 累积分布函数\n",
    "def cdf(gamma, epsilon):\n",
    "    normalizing_const = normalizing_constant(gamma, epsilon)\n",
    "    def normalized_cdf(x):\n",
    "        if x < epsilon:\n",
    "            return 0\n",
    "        elif x >= 1:\n",
    "            return 1\n",
    "        a = x**(1 - gamma) - epsilon**(1 - gamma)\n",
    "        b = normalizing_const * (1 - gamma)\n",
    "        return a / b\n",
    "    return normalized_cdf\n",
    "\n",
    "# 逆变换抽样\n",
    "def inv_cdf(gamma, epsilon):\n",
    "    normalizing_const = normalizing_constant(gamma, epsilon)\n",
    "    def normalized_inv_cdf(x):\n",
    "        if not 0 <= x <= 1:\n",
    "            raise ValueError()\n",
    "        a = x * normalizing_const * (1 - gamma)\n",
    "        b = epsilon**(1 - gamma)\n",
    "        return (a + b)**(1 / (1 - gamma))\n",
    "    return normalized_inv_cdf\n",
    "\n",
    "class simplex_vertex:\n",
    "    def __init__(self, vertex_id, activity):\n",
    "        self.act = activity\n",
    "        self.name = vertex_id\n",
    "\n",
    "def add_k_edges(n, e, tgraph):  # 往图中添加边\n",
    "    new_neigh = map(lambda x: [n, x], e)\n",
    "    tgraph.add_edges_from(new_neigh)\n",
    "    return tgraph\n",
    "\n",
    "\n",
    "class model(object):\n",
    "    def __init__(self, vertex_dict, m , eta, del_t, n, T, p, delta, beta, mu, last_t, I_0):\n",
    "        self.vertex_dict = vertex_dict\n",
    "        self.m = m           #产生m条边\n",
    "        self.eta = eta\n",
    "        self.del_t = del_t\n",
    "        self.n = n            #节点数\n",
    "        self.T = T            #演化的时间步\n",
    "        self.p = p            #A类人的比例\n",
    "        self.delta = delta    #减少的连边比例\n",
    "        self.delta_m = int(delta * m)\n",
    "        self.last_t = last_t  #最后记录的时间步\n",
    "        self.I_0 = I_0        #初始感染种子数\n",
    "        self.beta = beta      #感染率\n",
    "        self.mu = mu          #恢复率\n",
    "    def initial(self):\n",
    "        sAgent = set()\n",
    "        iAgent = set()\n",
    "        asAgent = set()   #a 为风险者，不会减少连边\n",
    "        bsAgent = set()   #b 为担忧者，会减少连边\n",
    "        A_0 = int(self.p * self.n)   #A类人有p*n\n",
    "        for node in self.vertex_dict.keys():\n",
    "            sAgent.add(node)\n",
    "        for _ in range(I_0):\n",
    "            to_infect = random.choice(list(sAgent))\n",
    "            iAgent.add(to_infect)\n",
    "            sAgent.remove(to_infect)\n",
    "        for bnodes in self.vertex_dict.keys():\n",
    "            bsAgent.add(bnodes)\n",
    "        for _ in range(A_0):\n",
    "            to_a = random.choice(list(bsAgent))\n",
    "            asAgent.add(to_a)\n",
    "            bsAgent.remove(to_a)\n",
    "        aiAgent = asAgent & iAgent\n",
    "        biAgent = bsAgent & iAgent\n",
    "        asAgent = asAgent - aiAgent\n",
    "        bsAgent = bsAgent - biAgent\n",
    "        return asAgent, bsAgent, aiAgent, biAgent\n",
    "    def reduce_m(self):\n",
    "        x = self.initial()\n",
    "        forward_asnodes = x[0]\n",
    "        forward_bsnodes = x[1]\n",
    "        forward_ainodes = x[2]\n",
    "        forward_binodes = x[3]\n",
    "        Ai_frac = 0\n",
    "        Bi_frac = 0\n",
    "        for t in range(self.T):\n",
    "            if not forward_ainodes | forward_binodes:\n",
    "                break\n",
    "            forward_as = set()\n",
    "            forward_bs = set()\n",
    "            forward_ai = set()\n",
    "            forward_bi = set()\n",
    "            tgraph = nx.Graph()\n",
    "            tgraph.add_nodes_from(self.vertex_dict.keys())\n",
    "            for node in forward_asnodes:\n",
    "                tgraph.nodes[node]['type'] = 'A'\n",
    "                tgraph.nodes[node]['state'] = 'S'\n",
    "                tgraph.nodes[node]['activity'] = self.vertex_dict[node].act\n",
    "                forward_as.add(node)\n",
    "            for i in forward_bsnodes:\n",
    "                tgraph.nodes[i]['type'] = 'B'\n",
    "                tgraph.nodes[i]['state'] = 'S'\n",
    "                tgraph.nodes[i]['activity'] = self.vertex_dict[i].act\n",
    "                forward_bs.add(i)\n",
    "            for a in forward_ainodes:\n",
    "                tgraph.nodes[a]['type'] = 'A'\n",
    "                tgraph.nodes[a]['state'] = 'I'\n",
    "                tgraph.nodes[a]['activity'] = self.vertex_dict[a].act\n",
    "                forward_ai.add(a)\n",
    "            for b in forward_binodes:\n",
    "                tgraph.nodes[b]['type'] = 'B'\n",
    "                tgraph.nodes[b]['state'] = 'I'\n",
    "                tgraph.nodes[b]['activity'] = self.vertex_dict[b].act\n",
    "                forward_bi.add(b)\n",
    "            for n1 in forward_asnodes|forward_ainodes:\n",
    "                if np.random.rand() <= tgraph.nodes[n1]['activity'] * self.eta * self.del_t:\n",
    "                    nodes = list(self.vertex_dict.keys())\n",
    "                    nodes.remove(n1)\n",
    "                    for i in sorted(nx.neighbors(tgraph, n1)):\n",
    "                        nodes.remove(i)\n",
    "                    neigh = random.sample(nodes, self.m)\n",
    "                    tgraph = add_k_edges(n1, neigh, tgraph)\n",
    "            for n2 in forward_bsnodes|forward_binodes:\n",
    "                if np.random.rand() <= tgraph.nodes[n2]['activity'] * self.eta * self.del_t:\n",
    "                    nodes = list(self.vertex_dict.keys())\n",
    "                    nodes.remove(n2)\n",
    "                    for i in sorted(nx.neighbors(tgraph, n2)):\n",
    "                        nodes.remove(i)\n",
    "                    neigh = random.sample(nodes, self.delta_m)\n",
    "                    tgraph = add_k_edges(n2, neigh, tgraph)\n",
    "            for node_as in forward_asnodes:\n",
    "                node_s_neighbors = sorted(nx.neighbors(tgraph, node_as))\n",
    "                i = 0\n",
    "                infected = False\n",
    "                while i < len(node_s_neighbors):\n",
    "                    if tgraph.nodes[node_s_neighbors[i]]['state'] == 'I':\n",
    "                        infected = np.random.random() <= self.beta\n",
    "                        if infected == True: break\n",
    "                    i += 1\n",
    "                if infected:\n",
    "                    forward_ai.add(node_as)\n",
    "                    forward_as.remove(node_as)\n",
    "            for node_bs in forward_bsnodes:\n",
    "                node_s_neighbors = sorted(nx.neighbors(tgraph, node_bs))\n",
    "                i = 0\n",
    "                infected = False\n",
    "                while i < len(node_s_neighbors):\n",
    "                    if tgraph.nodes[node_s_neighbors[i]]['state'] == 'I':\n",
    "                        infected = np.random.random() <= self.beta\n",
    "                        if infected == True: break\n",
    "                    i += 1\n",
    "                if infected:\n",
    "                    forward_bi.add(node_bs)\n",
    "                    forward_bs.remove(node_bs)\n",
    "            for node_ai in forward_ainodes:\n",
    "                if np.random.random() <= self.mu:\n",
    "                    forward_as.add(node_ai)\n",
    "                    forward_ai.remove(node_ai)\n",
    "            for node_bi in forward_binodes:\n",
    "                if np.random.random() <= self.mu:\n",
    "                    forward_bs.add(node_bi)\n",
    "                    forward_bi.remove(node_bi)\n",
    "            forward_asnodes = forward_as\n",
    "            forward_bsnodes = forward_bs\n",
    "            forward_ainodes = forward_ai\n",
    "            forward_binodes = forward_bi\n",
    "            if t >= self.last_t:\n",
    "                ai_simulation = float(len(forward_ainodes)) / self.n\n",
    "                Ai_frac += ai_simulation\n",
    "                bi_simulation = float(len(forward_binodes)) / self.n\n",
    "                Bi_frac += bi_simulation\n",
    "        return Ai_frac/(self.T-self.last_t), Bi_frac/(self.T-self.last_t)\n",
    "\n",
    "\n",
    "def pro_acts(N):\n",
    "    dist = []\n",
    "    for i in range(N):\n",
    "        dist.append(inv_cdf(2.2, 0.01)(random.uniform(0, 1)))\n",
    "    return dist\n",
    "\n",
    "beta_s = [0.05 * i for i in range(21)]\n",
    "p = 0.5\n",
    "N = pow(10, 5)\n",
    "n = 30000\n",
    "m = 4\n",
    "eta = 1\n",
    "del_t = 1\n",
    "T = 50000\n",
    "delta = 0.5\n",
    "mu = 0.1\n",
    "last_t = 49800\n",
    "I_0 = 300\n",
    "\n",
    "\n",
    "\n",
    "### 重复一次实验\n",
    "for beta in beta_s:\n",
    "    dist = pro_acts(N)\n",
    "    act = np.random.choice(dist, n)\n",
    "    dist = []\n",
    "    vertex_dict = {}\n",
    "    for j in range(n):\n",
    "        vertex_dict[j] = simplex_vertex(j, act[j])\n",
    "    uau_sis = model(vertex_dict, m=m, eta=eta, del_t=del_t, n=n, T=T, p=p, delta=delta, beta=beta, mu=mu,\n",
    "                    last_t=last_t, I_0=I_0)\n",
    "    mean_AI, mean_BI = uau_sis.reduce_m()\n",
    "    with open(r'C:\\Users\\dell\\Desktop\\hyx\\p=0.5,delta=0.5\\frequency.txt', 'a') as f:\n",
    "        f.write(str(beta) + ' ' + str(mean_AI) + ' '+ str(mean_BI) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
